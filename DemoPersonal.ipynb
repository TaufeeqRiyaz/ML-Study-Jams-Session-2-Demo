{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Demo for Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data for Machine Learning is generally stored as csv files.\n",
    "# You can think of them as excel files with rows and columns\n",
    "df = pd.read_csv('UniLinRegData.csv')\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can plot the data using matplotlib to get a nice graphical view of the problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 10))    # making the plot bigger\n",
    "plt.scatter(df['x1'], df['y'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This data looks a bit too good! That is because we generated it synthetically (using numpy!)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If a column of 1s is added to our data as x0, we will have an easier time dealing as vectors!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.insert(1, \"x0\", np.ones(df.shape[0]), True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to split the data to training and testing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_Train, X_Test, Y_Train, Y_Test = train_test_split(df[['x1', 'x0']], df['y'], test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_Train = X_Train.to_numpy()\n",
    "X_Test = X_Test.to_numpy()\n",
    "Y_Train = Y_Train.to_numpy().reshape(-1, 1)\n",
    "Y_Test = Y_Test.to_numpy().reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that now we have each <b>Datapoint</b> as a vector: $$x_{i} = \\begin{bmatrix} x1 \\\\ x0 \\end{bmatrix}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And, our dataset, Matrix X is: $$X = \\begin{bmatrix} x1_{1}&x0_{1}\\\\x1_{2}&x0_{2}\\\\.\\\\.\\\\x1_{n}&x0_{n} \\end{bmatrix}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or $$X = \\begin{bmatrix} x_{1}^T\\\\x_{2}^T\\\\.\\\\.\\\\x_{n}^T \\end{bmatrix}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And $$y = \\begin{bmatrix} y_{1} \\\\ y_{2} \\\\.\\\\. \\\\y_{n} \\end{bmatrix}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As always, we will make a class for our model. Inside it, we can easily declare methods and attributes to help train the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the class we have different methods like loss, gradient, etc. With what you have seen, try to write some code in numpy for the same! Take care of the dimensions (or the shape) of your numpy array!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here are the formulae for Linear Regression as discussed:\n",
    "$$\\text{Closed Form: } \\vec{\\theta} = (X^TX)^{-1}X^TY$$\n",
    "$$\\text{Loss: } J(\\vec{\\theta}) = (\\vec{y} - X\\vec{\\theta})^T(\\vec{y} - X\\vec{\\theta})$$\n",
    "$$\\text{Gradient: } \\frac{\\partial J}{\\partial \\vec{\\theta}} = 2(X^TX\\vec{\\theta} - X^T\\vec{y})$$\n",
    "$$\\text{Gradient Descent Update: } \\vec{\\theta_{new}} := \\vec{\\theta_{old}} - \\alpha \\frac{\\partial J}{\\partial \\vec{\\theta}}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some helpful numpy methods you can use:\n",
    "- Use .T after any vector/matrix to get its transpose\n",
    "- np.matmaul: for matrix multiplications and dot products\n",
    "- np.linalg.inv: to find matrix inverses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinReg:\n",
    "    def __init__(self, dimensions):\n",
    "        self.theta_grad = np.random.rand(dimensions, 1)\n",
    "        self.theta_closed = np.random.rand(dimensions, 1)\n",
    "\n",
    "    def closed_form(self, X, Y):\n",
    "        self.theta_closed = np.matmul(np.linalg.inv(np.matmul(X.T, X)), np.matmul(X.T, Y))\n",
    "        # return self.theta_closed\n",
    "        # pass\n",
    "\n",
    "    def loss(self, X, Y):\n",
    "        Loss = np.matmul((Y - np.matmul(X, self.theta_grad)).T, (Y - np.matmul(X, self.theta_grad)))\n",
    "\n",
    "        return np.squeeze(Loss)\n",
    "\n",
    "    def gradient(self, X, Y):\n",
    "        # dJ(w)/dw = 2*(XT*X*W - XT*Y)\n",
    "        gradient = 2 * (np.matmul(np.matmul(X.T, X), self.theta_grad) - np.matmul(X.T, Y))\n",
    "        return gradient\n",
    "        # pass\n",
    "\n",
    "    def update(self, X, Y, alpha):\n",
    "        # wnew = wold - alpha * dJ(w)/dw\n",
    "\n",
    "        self.theta_grad = self.theta_grad - alpha * self.gradient(X, Y)\n",
    "        # pass     \n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialise the Model\n",
    "\n",
    "We need to initialise the weights randomly, this step is done as the Model object is made. We need to pass in the number of features (columns) in X so that weights are initiated accordingly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LinRegModel = LinReg(X_Train.shape[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Here we find our closed form solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LinRegModel.closed_form(X_Train, Y_Train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = 50\n",
    "stop = 500\n",
    "multiplier = 3\n",
    "linX_CF = np.linspace(start, stop, multiplier*stop-start)\n",
    "linY_CF = linX_CF * LinRegModel.theta_closed[0] + LinRegModel.theta_closed[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.figure(figsize=(15, 10))\n",
    "plt.plot(linX_CF, linY_CF, '-r')\n",
    "plt.scatter(X_Train[:, 0], Y_Train)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.figure(figsize=(15, 10))\n",
    "plt.plot(linX_CF, linY_CF, '-r')\n",
    "plt.scatter(X_Test[:, 0], Y_Test)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Here we find our Gradient Descent Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_of_epochs = 50   # These are the number of repetitions we require in gradient descent\n",
    "alpha = 0.000000005\n",
    "\n",
    "for i in range(no_of_epochs):\n",
    "    Loss = LinRegModel.loss(X_Train, Y_Train)\n",
    "    if i % 5 == 0: print(\"Loss =\", Loss)\n",
    "    LinRegModel.update(X_Train, Y_Train, alpha)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us see how the line fits our data!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = 50\n",
    "stop = 500\n",
    "multiplier = 3\n",
    "linX_Gr = np.linspace(start, stop, multiplier*stop-start)\n",
    "linY_Gr = linX_Gr * LinRegModel.theta_grad[0] + LinRegModel.theta_grad[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.figure(figsize=(15, 10))\n",
    "plt.plot(linX_Gr, linY_Gr, '-r')\n",
    "plt.scatter(X_Train[:, 0], Y_Train)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.figure(figsize=(15, 10))\n",
    "plt.plot(linX_Gr, linY_Gr, '-r')\n",
    "plt.scatter(X_Test[:, 0], Y_Test)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Errors for Closed Form"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to write the predictions according to the X we use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Pred_Train_CF = np.matmul(X_Train, LinRegModel.theta_closed)\n",
    "Pred_Test_CF = np.matmul(X_Test, LinRegModel.theta_closed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"MSE for Training =\", mean_squared_error(Y_Train, Pred_Train_CF))\n",
    "print(\"MSE for Testing  =\", mean_squared_error(Y_Test, Pred_Test_CF))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Errors for Gradient Descent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to write the predictions according to the X we use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Pred_Train_Gr = np.matmul(X_Train, LinRegModel.theta_grad)\n",
    "Pred_Test_Gr = np.matmul(X_Test, LinRegModel.theta_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"MSE for Training =\", mean_squared_error(Y_Train, Pred_Train_Gr))\n",
    "print(\"MSE for Testing  =\", mean_squared_error(Y_Test, Pred_Test_Gr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let us put this against SciKit-Learn!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LinRegSKL = LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LinRegSKL.fit(X_Train, Y_Train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "theta_SKL = np.array([LinRegSKL.coef_[0, 0], LinRegSKL.intercept_[0]]).reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Pred_Train_SKL = np.matmul(X_Train, theta_SKL)\n",
    "Pred_Test_SKL = np.matmul(X_Test, theta_SKL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"MSE for Training =\", mean_squared_error(Y_Train, Pred_Train_SKL))\n",
    "print(\"MSE for Testing  =\", mean_squared_error(Y_Test, Pred_Test_SKL))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('ML-Study-Jams-Session1')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a7743d7d34a95fe5c97afd1a40917a03710d8c4556efb82adbf1ff8ee7a6c3cf"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
